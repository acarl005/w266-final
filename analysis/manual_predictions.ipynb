{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict, Counter\n",
    "from w266_common import utils, vocabulary, tf_embed_viz, patched_numpy_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_show = \"friends\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "root_path = Path().resolve().joinpath(\"..\")\n",
    "show_data_path = root_path.joinpath(\"scrape\", \"data\", tv_show, \"parsed\")\n",
    "embeddings_path = root_path.joinpath(\"embeddings\", \"newscrawl.300d.W.pos.vectors.gz\")\n",
    "embeddings_url = \"https://www.dropbox.com/s/kguufyc2xcdi8yk/lexvec.enwiki%2Bnewscrawl.300d.W.pos.vectors.gz?dl=1\"\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/work/analysis/../embeddings/newscrawl.300d.W.pos.vectors.gz\n"
     ]
    }
   ],
   "source": [
    "print(embeddings_path)\n",
    "\n",
    "if not os.path.isfile(embeddings_path):\n",
    "    print(\"downloading embeddings...\")\n",
    "    urllib.request.urlretrieve(embeddings_url, embeddings_path)\n",
    "\n",
    "# !gunzip {str(embeddings_path)} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog_datas = []\n",
    "\n",
    "for filename in os.listdir(show_data_path):\n",
    "    dialog_data = pd.read_csv(show_data_path.joinpath(filename), header=None, names=(\"speaker\", \"utterance\"))\n",
    "    dialog_data[\"episode\"] = filename.split(\".\")[0]\n",
    "    dialog_datas.append(dialog_data)\n",
    "    \n",
    "all_dialog_data = pd.concat(dialog_datas).dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speaker      55025\n",
      "utterance    55025\n",
      "episode      55025\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>utterance</th>\n",
       "      <th>episode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Phoebe</td>\n",
       "      <td>Oh, hey Joey.</td>\n",
       "      <td>1012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Joey</td>\n",
       "      <td>Uh, hey.</td>\n",
       "      <td>1012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Phoebe</td>\n",
       "      <td>Listen, I need to ask you something. Ok, you k...</td>\n",
       "      <td>1012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Joey</td>\n",
       "      <td>Yeah.</td>\n",
       "      <td>1012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Phoebe</td>\n",
       "      <td>Yeah. Well, uhm... listen he was supposed to g...</td>\n",
       "      <td>1012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  speaker                                          utterance episode\n",
       "0  Phoebe                                      Oh, hey Joey.    1012\n",
       "1    Joey                                           Uh, hey.    1012\n",
       "2  Phoebe  Listen, I need to ask you something. Ok, you k...    1012\n",
       "3    Joey                                              Yeah.    1012\n",
       "4  Phoebe  Yeah. Well, uhm... listen he was supposed to g...    1012"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(all_dialog_data.count())\n",
    "all_dialog_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_counts = Counter()\n",
    "for character in all_dialog_data.speaker:\n",
    "    character_counts[character] += 1\n",
    "    \n",
    "top_characters = character_counts.most_common(6)\n",
    "\n",
    "char_id_to_word = dict(enumerate([w for w, c in top_characters]))\n",
    "char_word_to_id = {v:k for k,v in char_id_to_word.items()}\n",
    "\n",
    "major_dialog_data = all_dialog_data[all_dialog_data.speaker.isin(char_word_to_id.keys())]\n",
    "\n",
    "utterance_tokenized = [word_tokenize(sentence) for sentence in major_dialog_data.utterance]\n",
    "vocab = vocabulary.Vocabulary(utils.canonicalize_word(w) for w in utils.flatten(utterance_tokenized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 40\n",
    "\n",
    "utterances_index = [vocab.words_to_ids(words) for words in utterance_tokenized]\n",
    "speaker_index = np.array([char_word_to_id[speaker] for speaker in major_dialog_data.speaker])\n",
    "utterances_index_nparray = np.zeros((len(utterances_index), max_len), dtype=np.int32)\n",
    "utterances_length = np.zeros([len(utterances_index)], dtype=np.int32)\n",
    "\n",
    "for i, row in enumerate(utterances_index):\n",
    "    cpy_len = min(len(row), max_len)\n",
    "    utterances_index_nparray[i,:cpy_len] = row[:cpy_len]\n",
    "    utterances_length[i] = cpy_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_check_df = pd.DataFrame()\n",
    "human_check_df['utterance'] = major_dialog_data.utterance\n",
    "human_check_df['utterance_tokenized'] = utterance_tokenized\n",
    "human_check_df['speaker'] = major_dialog_data.speaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>utterance_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19872</th>\n",
       "      <td>I still cannot believe you’re engaged!  Just ‘cause its happening so fast; not ‘cause you’re such a loser.</td>\n",
       "      <td>[I, still, can, not, believe, you, ’, re, engaged, !, Just, ‘, cause, its, happening, so, fast, ;, not, ‘, cause, you, ’, re, such, a, loser, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52827</th>\n",
       "      <td>But you-you-you came to see Lilly?</td>\n",
       "      <td>[But, you-you-you, came, to, see, Lilly, ?]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44527</th>\n",
       "      <td>Come on, show me.</td>\n",
       "      <td>[Come, on, ,, show, me, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23812</th>\n",
       "      <td>You pushed him!</td>\n",
       "      <td>[You, pushed, him, !]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29400</th>\n",
       "      <td>Could there be more Kims?</td>\n",
       "      <td>[Could, there, be, more, Kims, ?]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16405</th>\n",
       "      <td>Although, don’t feel like you can’t visit.</td>\n",
       "      <td>[Although, ,, don, ’, t, feel, like, you, can, ’, t, visit, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42587</th>\n",
       "      <td>Oh.</td>\n",
       "      <td>[Oh, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16720</th>\n",
       "      <td>I know.</td>\n",
       "      <td>[I, know, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34501</th>\n",
       "      <td>I’ll take a card.</td>\n",
       "      <td>[I, ’, ll, take, a, card, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50504</th>\n",
       "      <td>That is.</td>\n",
       "      <td>[That, is, .]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                        utterance  \\\n",
       "19872  I still cannot believe you’re engaged!  Just ‘cause its happening so fast; not ‘cause you’re such a loser.   \n",
       "52827                                                                          But you-you-you came to see Lilly?   \n",
       "44527                                                                                           Come on, show me.   \n",
       "23812                                                                                             You pushed him!   \n",
       "29400                                                                                   Could there be more Kims?   \n",
       "16405                                                                  Although, don’t feel like you can’t visit.   \n",
       "42587                                                                                                         Oh.   \n",
       "16720                                                                                                     I know.   \n",
       "34501                                                                                           I’ll take a card.   \n",
       "50504                                                                                                    That is.   \n",
       "\n",
       "                                                                                                                                    utterance_tokenized  \n",
       "19872  [I, still, can, not, believe, you, ’, re, engaged, !, Just, ‘, cause, its, happening, so, fast, ;, not, ‘, cause, you, ’, re, such, a, loser, .]  \n",
       "52827                                                                                                       [But, you-you-you, came, to, see, Lilly, ?]  \n",
       "44527                                                                                                                        [Come, on, ,, show, me, .]  \n",
       "23812                                                                                                                             [You, pushed, him, !]  \n",
       "29400                                                                                                                 [Could, there, be, more, Kims, ?]  \n",
       "16405                                                                                    [Although, ,, don, ’, t, feel, like, you, can, ’, t, visit, .]  \n",
       "42587                                                                                                                                           [Oh, .]  \n",
       "16720                                                                                                                                      [I, know, .]  \n",
       "34501                                                                                                                      [I, ’, ll, take, a, card, .]  \n",
       "50504                                                                                                                                     [That, is, .]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 1000\n",
    "\n",
    "human_check_df_sample = human_check_df.sample(10)\n",
    "\n",
    "human_check_df_sample[['utterance', 'utterance_tokenized']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utterance</th>\n",
       "      <th>utterance_tokenized</th>\n",
       "      <th>speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19872</th>\n",
       "      <td>I still cannot believe you’re engaged!  Just ‘cause its happening so fast; not ‘cause you’re such a loser.</td>\n",
       "      <td>[I, still, can, not, believe, you, ’, re, engaged, !, Just, ‘, cause, its, happening, so, fast, ;, not, ‘, cause, you, ’, re, such, a, loser, .]</td>\n",
       "      <td>Phoebe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52827</th>\n",
       "      <td>But you-you-you came to see Lilly?</td>\n",
       "      <td>[But, you-you-you, came, to, see, Lilly, ?]</td>\n",
       "      <td>Phoebe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44527</th>\n",
       "      <td>Come on, show me.</td>\n",
       "      <td>[Come, on, ,, show, me, .]</td>\n",
       "      <td>Rachel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23812</th>\n",
       "      <td>You pushed him!</td>\n",
       "      <td>[You, pushed, him, !]</td>\n",
       "      <td>Joey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29400</th>\n",
       "      <td>Could there be more Kims?</td>\n",
       "      <td>[Could, there, be, more, Kims, ?]</td>\n",
       "      <td>Chandler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16405</th>\n",
       "      <td>Although, don’t feel like you can’t visit.</td>\n",
       "      <td>[Although, ,, don, ’, t, feel, like, you, can, ’, t, visit, .]</td>\n",
       "      <td>Phoebe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42587</th>\n",
       "      <td>Oh.</td>\n",
       "      <td>[Oh, .]</td>\n",
       "      <td>Rachel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16720</th>\n",
       "      <td>I know.</td>\n",
       "      <td>[I, know, .]</td>\n",
       "      <td>Phoebe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34501</th>\n",
       "      <td>I’ll take a card.</td>\n",
       "      <td>[I, ’, ll, take, a, card, .]</td>\n",
       "      <td>Chandler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50504</th>\n",
       "      <td>That is.</td>\n",
       "      <td>[That, is, .]</td>\n",
       "      <td>Phoebe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                        utterance  \\\n",
       "19872  I still cannot believe you’re engaged!  Just ‘cause its happening so fast; not ‘cause you’re such a loser.   \n",
       "52827                                                                          But you-you-you came to see Lilly?   \n",
       "44527                                                                                           Come on, show me.   \n",
       "23812                                                                                             You pushed him!   \n",
       "29400                                                                                   Could there be more Kims?   \n",
       "16405                                                                  Although, don’t feel like you can’t visit.   \n",
       "42587                                                                                                         Oh.   \n",
       "16720                                                                                                     I know.   \n",
       "34501                                                                                           I’ll take a card.   \n",
       "50504                                                                                                    That is.   \n",
       "\n",
       "                                                                                                                                    utterance_tokenized  \\\n",
       "19872  [I, still, can, not, believe, you, ’, re, engaged, !, Just, ‘, cause, its, happening, so, fast, ;, not, ‘, cause, you, ’, re, such, a, loser, .]   \n",
       "52827                                                                                                       [But, you-you-you, came, to, see, Lilly, ?]   \n",
       "44527                                                                                                                        [Come, on, ,, show, me, .]   \n",
       "23812                                                                                                                             [You, pushed, him, !]   \n",
       "29400                                                                                                                 [Could, there, be, more, Kims, ?]   \n",
       "16405                                                                                    [Although, ,, don, ’, t, feel, like, you, can, ’, t, visit, .]   \n",
       "42587                                                                                                                                           [Oh, .]   \n",
       "16720                                                                                                                                      [I, know, .]   \n",
       "34501                                                                                                                      [I, ’, ll, take, a, card, .]   \n",
       "50504                                                                                                                                     [That, is, .]   \n",
       "\n",
       "        speaker  \n",
       "19872    Phoebe  \n",
       "52827    Phoebe  \n",
       "44527    Rachel  \n",
       "23812      Joey  \n",
       "29400  Chandler  \n",
       "16405    Phoebe  \n",
       "42587    Rachel  \n",
       "16720    Phoebe  \n",
       "34501  Chandler  \n",
       "50504    Phoebe  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_check_df_sample[['utterance', 'utterance_tokenized', 'speaker']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
